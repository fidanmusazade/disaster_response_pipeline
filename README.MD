# Disaster Response Pipeline Project

## Overview
There is a high need to classify tweets as whether they indicate any type of disaster or no. The motivation behind this project is to define whether a given tweet signals a disaster. Data is collected from Figure Eight. The question has been answered by creating a model to classify those messages.
However, as the dataset is imbalanced and there are more tweets not indicating a disaster rather that indicating. This issue could have been addressed in more detail in the future.

## Instructions:
1. Run the following commands in the project's root directory to set up your database and model.

    - To run ETL pipeline that cleans data and stores in database
        `python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db`
    - To run ML pipeline that trains classifier and saves
        `python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl`

2. Run the following command in the app's directory to run your web app.
    `python run.py`

3. Go to http://0.0.0.0:3001/

The list of required libraries can be found is requirements.txt file.

## Project Motivation
This project is a part of Udacity Data Scientist nanodegree and is aimed at classifying a message as a particular type of disaster to be classified as.

## File Descriptions
1. The files in data folder include datasets provided by Figure 8, ETL pipeline and the sqlite database containing clean data (generated by the ETL pipeline)
2. Models folder includes ML pipeline that generates a model and saves it into pickle file.
3. App folder contains web app with charts and opportunity to classify a message.

## Results
The results can be observed by running app.py file

## Licensing, Authors, Acknowledgements
All data is provided by Figure Eight. The project was completed with the help of Udacity.
