# Disaster Response Pipeline Project

### Instructions:
1. Run the following commands in the project's root directory to set up your database and model.

    - To run ETL pipeline that cleans data and stores in database
        `python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db`
    - To run ML pipeline that trains classifier and saves
        `python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl`

2. Run the following command in the app's directory to run your web app.
    `python run.py`

3. Go to http://0.0.0.0:3001/

## Project Motivation
This project is a part of Udacity Data Scientist nanodegree and is aimed at classifying a message as a particular type of disaster to be acknowledged to.

## File Descriptions
1. The files in data folder include datasets provided by Figure 8, ETL pipeline and the sqlite database containing clean data (generated by the ETL pipeline)
2. Models folder includes ML pipeline that generates a model and saves it into pickle file.
3. App folder contains web app with charts and opportunity to classify a message.

## Results
The results can be observed by running app.py file

## Licensing, Authors, Acknowledgements
All data is provided by Figure Eight. The project was completed with the help of Udacity.
